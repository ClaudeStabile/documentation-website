"use strict";(self.webpackChunknewdoc=self.webpackChunknewdoc||[]).push([[367],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>m});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=c(a),m=r,h=u["".concat(l,".").concat(m)]||u[m]||d[m]||i;return a?n.createElement(h,o(o({ref:t},p),{},{components:a})):n.createElement(h,o({ref:t},p))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var c=2;c<i;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},491:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var n=a(7462),r=(a(7294),a(3905));const i={sidebar_label:"LinTO Platform STT",sidebar_position:1},o="LinTO Platform STT (aka LinSTT) Automatic Speech Recognition",s={unversionedId:"developpers/apis/ASR/ASR",id:"developpers/apis/ASR/ASR",title:"LinTO Platform STT (aka LinSTT) Automatic Speech Recognition",description:"What is an ASR system?",source:"@site/docs/developpers/apis/ASR/ASR.md",sourceDirName:"developpers/apis/ASR",slug:"/developpers/apis/ASR/",permalink:"/docs/developpers/apis/ASR/",draft:!1,editUrl:"https://github.com/linto-ai/documentation-website/tree/source/docs/developpers/apis/ASR/ASR.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_label:"LinTO Platform STT",sidebar_position:1},sidebar:"devSidebar",previous:{title:"On premises Cognitive APIs",permalink:"/docs/developpers/apis/"},next:{title:"Run with Docker",permalink:"/docs/developpers/apis/ASR/dockerrun"}},l={},c=[{value:"What is an ASR system?",id:"what-is-an-asr-system",level:2},{value:"Main features",id:"main-features",level:2},{value:"Acoustic Model",id:"acoustic-model",level:2},{value:"Decoding Graph",id:"decoding-graph",level:2},{value:"Diarization (speaker clustering)",id:"diarization-speaker-clustering",level:2}],p={toc:c};function d(e){let{components:t,...i}=e;return(0,r.kt)("wrapper",(0,n.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"linto-platform-stt-aka-linstt-automatic-speech-recognition"},"LinTO Platform STT (aka LinSTT) Automatic Speech Recognition"),(0,r.kt)("h2",{id:"what-is-an-asr-system"},"What is an ASR system?"),(0,r.kt)("p",null,"Generally, Automatic Speech Recognition (ASR) is the task of recognition and translation of spoken language into text. Our ASR system takes advantages from the recent advances in machine learning technologies and in particular deep learning ones (TDNN, LSTM, attentation-based architecture). The core of our system consists of two main components: an acoustic model and a decoding graph. A high-performance ASR system relies on an accurate acoustic model as well as a perfect decoding graph."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"LinSTT",src:a(2749).Z,width:"4175",height:"1150"})),(0,r.kt)("h2",{id:"main-features"},"Main features"),(0,r.kt)("p",null,"The main features of our speech-to-text transcriber are:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Speech decoder using the recent advanced modeling technologies -- Deep Neural Networks."),(0,r.kt)("li",{parentName:"ul"},"Compute the time stamp, i.e. the start and end time, for every word that was recognized."),(0,r.kt)("li",{parentName:"ul"},"Perform the speaker diarization to assign speech signals to speakers engaged in dialog."),(0,r.kt)("li",{parentName:"ul"},"The real number of speakers could be provided for high speaker diarization performance."),(0,r.kt)("li",{parentName:"ul"},"Two output formats are allowed: a simple transcription using the Response Content Type ",(0,r.kt)("inlineCode",{parentName:"li"},"text/plain"),", or extended transcription with metadata using ",(0,r.kt)("inlineCode",{parentName:"li"},"application/json"),".")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"LinSTT",src:a(9402).Z,width:"2461",height:"978"}),"  "),(0,r.kt)("h2",{id:"acoustic-model"},"Acoustic Model"),(0,r.kt)("p",null,"The Acoustic Model (AM) is used to represent the relationship between the speech signal and the phonemes that are basic units of sound acoustically realized in a language. Using an annotated speech corpus, this model is trained on a set of audio recordings and their corresponding transcripts."),(0,r.kt)("p",null,"You can find a description and a download link of the available models here: ",(0,r.kt)("a",{parentName:"p",href:"ASR/models"},"Acoustic Models")),(0,r.kt)("h2",{id:"decoding-graph"},"Decoding Graph"),(0,r.kt)("p",null,"The Decoding Graph (DG) aims at capturing automatically the linguistic knowledge (syntax, semantics, etc.) about the target language from a large corpus text and helps to select the best option for a word transcription."),(0,r.kt)("p",null,"You can download the available graphs from here: ",(0,r.kt)("a",{parentName:"p",href:"ASR/models"},"Decoding Graphs")),(0,r.kt)("h2",{id:"diarization-speaker-clustering"},"Diarization (speaker clustering)"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/linto-ai/linto-platform-diarization"},"Documentation attached with source code")))}d.isMDXComponent=!0},2749:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/linstt-ea31d20fcc26b16c5de50a5446bb0c7a.png"},9402:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/stt-ba040793ce39249aa7070447b334a712.png"}}]);