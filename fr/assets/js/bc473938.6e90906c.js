"use strict";(self.webpackChunknewdoc=self.webpackChunknewdoc||[]).push([[8948],{3905:(e,r,t)=>{t.d(r,{Zo:()=>c,kt:()=>f});var n=t(7294);function a(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function o(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function s(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?o(Object(t),!0).forEach((function(r){a(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function i(e,r){if(null==e)return{};var t,n,a=function(e,r){if(null==e)return{};var t,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)t=o[n],r.indexOf(t)>=0||(a[t]=e[t]);return a}(e,r);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)t=o[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var p=n.createContext({}),l=function(e){var r=n.useContext(p),t=r;return e&&(t="function"==typeof e?e(r):s(s({},r),e)),t},c=function(e){var r=l(e.components);return n.createElement(p.Provider,{value:r},e.children)},u={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},d=n.forwardRef((function(e,r){var t=e.components,a=e.mdxType,o=e.originalType,p=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),d=l(t),f=a,m=d["".concat(p,".").concat(f)]||d[f]||u[f]||o;return t?n.createElement(m,s(s({ref:r},c),{},{components:t})):n.createElement(m,s({ref:r},c))}));function f(e,r){var t=arguments,a=r&&r.mdxType;if("string"==typeof e||a){var o=t.length,s=new Array(o);s[0]=d;var i={};for(var p in r)hasOwnProperty.call(r,p)&&(i[p]=r[p]);i.originalType=e,i.mdxType="string"==typeof e?e:a,s[1]=i;for(var l=2;l<o;l++)s[l]=t[l];return n.createElement.apply(null,s)}return n.createElement.apply(null,t)}d.displayName="MDXCreateElement"},9074:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>p,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>l});var n=t(7462),a=(t(7294),t(3905));const o={sidebar_label:"Run with LinTO platform server",sidebar_position:3},s="Transcription services on LinTO platform server",i={unversionedId:"developpers/apis/ASR/platformrun",id:"developpers/apis/ASR/platformrun",title:"Transcription services on LinTO platform server",description:"If you already deployed a LinTO platform server instance, and as the platform leverages the usage of transcription services, you already have all the tools required to spawn new Transcription services for any needs as scalable docker swarm services. You might simply use your LinTO Platform Service Manager API to achieve this. Your LinTO platform server also embeds a full-figured NLU leveraging a custom deployment of Voyages SNCF TOCK for any language understanding that relates to chatbots or virtual agents.",source:"@site/docs/developpers/apis/ASR/platformrun.md",sourceDirName:"developpers/apis/ASR",slug:"/developpers/apis/ASR/platformrun",permalink:"/fr/docs/developpers/apis/ASR/platformrun",draft:!1,editUrl:"https://github.com/linto-ai/documentation-website/tree/source/docs/developpers/apis/ASR/platformrun.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_label:"Run with LinTO platform server",sidebar_position:3},sidebar:"devSidebar",previous:{title:"Models download",permalink:"/fr/docs/developpers/apis/ASR/models"},next:{title:"Natural Language Processing",permalink:"/fr/docs/developpers/apis/NLP/"}},p={},l=[],c={toc:l};function u(e){let{components:r,...t}=e;return(0,a.kt)("wrapper",(0,n.Z)({},c,t,{components:r,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"transcription-services-on-linto-platform-server"},"Transcription services on LinTO platform server"),(0,a.kt)("admonition",{type:"tip"},(0,a.kt)("p",{parentName:"admonition"},"If you already deployed a LinTO platform server instance, and as the platform leverages the usage of ",(0,a.kt)("strong",{parentName:"p"},"transcription services"),", you already have all the tools required to spawn ",(0,a.kt)("strong",{parentName:"p"},"new Transcription services")," for any needs as scalable ",(0,a.kt)("strong",{parentName:"p"},"docker swarm services"),". You might simply use your ",(0,a.kt)("a",{parentName:"p",href:"/docs/developpers/agent/server/post_install/"},"LinTO Platform Service Manager API")," to achieve this. Your LinTO platform server also embeds a full-figured NLU leveraging a custom deployment of ",(0,a.kt)("a",{parentName:"p",href:"https://doc.tock.ai/"},"Voyages SNCF TOCK")," for any language understanding that relates to chatbots or virtual agents.")),(0,a.kt)("admonition",{type:"info"},(0,a.kt)("p",{parentName:"admonition"},"Your LinTO platform server instance do not leverages the use of Diarization nor Punctuation or NLP APIs as it focuses on virtual agents and smart assistants. The Platform Service Manager ",(0,a.kt)("strong",{parentName:"p"},"currently do not enables deployments of this kind of tasks"),". However you might use the following documentation to deploy, and maybe use them in your custom LinTO Virtual Agents applications")))}u.isMDXComponent=!0}}]);